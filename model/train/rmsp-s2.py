import tensorflow

def train(self, data, config=None):

    batch_size = 32
    epochs = 1
    data_augmentation = False
    opt = tensorflow.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)
    n_workers = 2
    x_train = data.get_train_data().x
    y_train = data.get_train_data().y
    
    self.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])
    
    if not data_augmentation:
        print('Not using data augmentation.')
        self.fit(x_train, y_train,
                  batch_size=batch_size,
                  epochs=epochs,
                  shuffle=True)
    else:
        print('Using real-time data augmentation.')
        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(
            featurewise_center=False,  # set input mean to 0 over the dataset
            samplewise_center=False,  # set each sample mean to 0
            featurewise_std_normalization=False,  # divide inputs by std of the dataset
            samplewise_std_normalization=False,  # divide each input by its std
            zca_whitening=False,  # apply ZCA whitening
            zca_epsilon=1e-06,  # epsilon for ZCA whitening
            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
            # randomly shift images horizontally (fraction of total width)
             width_shift_range=0.1,
            # randomly shift images vertically (fraction of total height)
             height_shift_range=0.1,
            shear_range=0.,  # set range for random shear
            zoom_range=0.,  # set range for random zoom
            channel_shift_range=0.,  # set range for random channel shifts
            # set mode for filling points outside the input boundaries
             fill_mode='nearest',
            cval=0.,  # value used for fill_mode = "constant"
            horizontal_flip=True,  # randomly flip images
            vertical_flip=False,  # randomly flip images
            # set rescaling factor (applied before any other transformation)
             rescale=None,
            # set function that will be applied on each input
             preprocessing_function=None,
            # image data format, either "channels_first" or "channels_last"
             data_format=None,
            # fraction of images reserved for validation (strictly between 0 and 1)
             validation_split=0.0)

        # Compute quantities required for feature-wise normalization
        # (std, mean, and principal components if ZCA whitening is applied).
        datagen.fit(x_train)

        # Fit the model on the batches generated by datagen.flow().
        self.fit_generator(datagen.flow(x_train, y_train,
                                         batch_size=batch_size),
                            epochs=epochs,
                            workers=n_workers)

    return self.evaluate(data.get_eval_data().x, data.get_eval_data().y)[1]
